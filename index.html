<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>PONP</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!--    <meta property="og:image" content="https://probnerf.github.io/img/titlecard.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630"> -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://its-gucci.github.io/hypfm">
    <meta property="og:title" content="Foundation Models Secretly Understand Neural Network Weights: Enhancing Hypernetwork Architectures with Foundation Models">
    <meta property="og:description" content="Using foundation models with linear probes as hypernetworks improves performance in many facets over traditional hypernetwork approaches.">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Foundation Models Secretly Understand Neural Network Weights: Enhancing Hypernetwork Architectures with Foundation Models">
    <meta name="twitter:description" content="Using foundation models with linear probes as hypernetworks improves performance in many facets over traditional hypernetwork approaches.">
<!--    <meta name="twitter:image" content="https://dorverbin.github.io/refnerf/img/refnerf_titlecard.jpg"> -->


    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Foundation Models Secretly Understand Neural Network Weights: Enhancing Hypernetwork Architectures with Foundation Models<br>
                <small>
                    ICLR 2025 (Poster)
                </small>
            </h2>
        </div>

        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                        <li>
                            <a style="text-decoration:none" href="https://its-gucci.github.io/">
                              Jeffrey Gu
                            </a>
                            <br>Stanford ICME
                        </li>
                        <li>
                            <a style="text-decoration:none" href="https://ai.stanford.edu/~syyeung/">
                              Serena Yeung
                            </a>
                            <br>Stanford CS
                        </li>
                </ul>
            </div>
        </div>

        <div class="row">
                <div class="col-sm-6 col-sm-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <img src="./images/paper.png" alt="paper" height="60">
                                <h4><strong>Paper (coming soon!)</strong></h4>
                        </li>                            
                        <li>
                            <img src="./images/github-mark.png" alt="code" height="60">
                                <h4><strong>Code (coming soon!)</strong></h4>
                        </li>
                    </ul>
                </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                  Large pre-trained models, or foundation models, have shown impressive performance when adapted to a variety of downstream tasks, often out-performing specialized models. Hypernetworks, neural networks that generate some or all of the parameters of another neural network, have become an increasingly important technique for conditioning and generalizing implicit neural representations (INRs), which represent signals or objects such as audio or 3D shapes using a neural network. However, despite the potential benefits of incorporating foundation models in hypernetwork methods, this research direction has not been investigated, likely due to the dissimilarity of the weight generation task with other visual tasks. To address this gap, we (1) show how foundation models can improve hypernetworks with Transformer-based architectures, (2) provide an empirical analysis of the benefits of foundation models for hypernetworks through the lens of the generalizable INR task, showing that leveraging foundation models improves performance, generalizability, and data efficiency across a variety of algorithms and modalities. We also provide further analysis in examining the design space of foundation model-based hypernetworks, including examining the choice of foundation models, algorithms, and the effect of scaling foundation models.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                    <pre>
@article{gu2023foundation,
  title={Foundation Models Secretly Understand Neural Network Weights: Enhancing Hypernetwork Architectures with Foundation Models},
  author={Gu, Jeffrey and Yeung, Serena},
  year={2025}
}</pre>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
             
                    <br>
                The website template was borrowed from <a href="https://probnerf.github.io/">ProbNeRF</a>.
                </p>
            </div>
        </div>
    </div>


</body></html>
